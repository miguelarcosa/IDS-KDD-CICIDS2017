{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cfb0aa-65fd-4559-9f3e-f68d935f24af",
   "metadata": {},
   "source": [
    "# CICIDS2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63150774-cd51-4b1c-85b0-97f8c79e869e",
   "metadata": {},
   "source": [
    "### Logistic Regression (no SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4d4565-7218-4ae0-9d89-4b726bf625db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics ===\n",
      "Accuracy      : 0.9878\n",
      "Precision     : 0.9722\n",
      "Recall        : 0.9783\n",
      "F1-Score      : 0.9752\n",
      "FAR           : 0.0091\n",
      "AUC           : 0.9961\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 313619, FP: 2895\n",
      "FN: 2245, TP: 101237\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# === 0. Reproducibility ===\n",
    "np.random.seed(42)\n",
    "\n",
    "# === 1. Load unified, normalized dataset ===\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2. Split features and label ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# (Opcional pero recomendado): convertir ±inf a NaN antes de imputar\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3. Train/Test split (stratified) ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Pipeline: Imputer (median) + Logistic Regression ===\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Predict and calculate metrics ===\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# === 6. Confusion matrix and metrics ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "# === 7. Print results ===\n",
    "print(\"=== Classification Metrics ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0fe9f-75ea-4d7a-a78e-27dcbabcb0db",
   "metadata": {},
   "source": [
    "### Logistic Regression (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cbae4dd-7e1a-474d-94c4-340ef25712fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (LogReg + SMOTE) ===\n",
      "Accuracy      : 0.9862\n",
      "Precision     : 0.9623\n",
      "Recall        : 0.9824\n",
      "F1-Score      : 0.9723\n",
      "FAR           : 0.0126\n",
      "AUC           : 0.9962\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 312536, FP: 3978\n",
      "FN: 1817, TP: 101665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline  # ¡Ojo! el Pipeline de imblearn\n",
    "\n",
    "# === 0. Reproducibility ===\n",
    "np.random.seed(42)\n",
    "\n",
    "# === 1. Load unified, normalized dataset ===\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2. Split features and label ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Convertir ±inf a NaN antes de imputar\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3. Train/Test split (stratified) ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Pipeline: Imputer -> SMOTE -> Logistic Regression ===\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Predict and calculate metrics ===\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# === 6. Confusion matrix and metrics ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "# === 7. Print results ===\n",
    "print(\"=== Classification Metrics (LogReg + SMOTE) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6837cb-ab33-4f65-bf6c-517923a4a012",
   "metadata": {},
   "source": [
    "## Naive Bayes (NO SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58350bdb-47db-48d4-870a-4459103facb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (GaussianNB, no SMOTE) ===\n",
      "Accuracy      : 0.8565\n",
      "Precision     : 0.6364\n",
      "Recall        : 0.9742\n",
      "F1-Score      : 0.7699\n",
      "FAR           : 0.1820\n",
      "AUC           : 0.9711\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 258924, FP: 57590\n",
      "FN: 2668, TP: 100814\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# === 0. Reproducibilidad ===\n",
    "np.random.seed(42)\n",
    "\n",
    "# === 1. Cargar dataset unificado y normalizado ===\n",
    "# Debe tener todas las columnas numéricas y 'Label' (0/1) al final\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2. Separar features y label ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Manejo de infinitos -> NaN (para que el imputer los resuelva)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3. Split estratificado y reproducible ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Pipeline: Imputer (median) -> GaussianNB ===\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"nb\", GaussianNB())\n",
    "])\n",
    "\n",
    "# Entrenamiento\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Predicción y métricas ===\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]  # probas para AUC\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "# === 6. Resultados ===\n",
    "print(\"=== Classification Metrics (GaussianNB, no SMOTE) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b7063-ab97-496c-9d0c-f5436ed3e858",
   "metadata": {},
   "source": [
    "## Naive Bayes (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6b1ddb-1707-4bc4-a5a2-86ae74d3f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (GaussianNB + SMOTE) ===\n",
      "Accuracy      : 0.8564\n",
      "Precision     : 0.6362\n",
      "Recall        : 0.9742\n",
      "F1-Score      : 0.7697\n",
      "FAR           : 0.1821\n",
      "AUC           : 0.9686\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 258862, FP: 57652\n",
      "FN: 2671, TP: 100811\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline  # importante: Pipeline de imblearn\n",
    "\n",
    "# === 0. Reproducibilidad ===\n",
    "np.random.seed(42)\n",
    "\n",
    "# === 1. Cargar dataset unificado y normalizado ===\n",
    "# Debe tener todas las columnas numéricas y 'Label' (0/1) al final\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2. Separar features y label ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Manejo de infinitos -> NaN (para que el imputer los resuelva)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3. Split estratificado y reproducible ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Pipeline: Imputer (median) -> SMOTE -> GaussianNB ===\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"nb\", GaussianNB())\n",
    "])\n",
    "\n",
    "# Entrenamiento\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Predicción y métricas ===\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "# === 6. Resultados ===\n",
    "print(\"=== Classification Metrics (GaussianNB + SMOTE) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a960b-84de-48c7-b071-489841b160f9",
   "metadata": {},
   "source": [
    "### LDA (no SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f400c369-9e07-4e6f-b55a-979d84894e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (LDA) ===\n",
      "Accuracy      : 0.9784\n",
      "Precision     : 0.9426\n",
      "Recall        : 0.9715\n",
      "F1-Score      : 0.9569\n",
      "FAR           : 0.0193\n",
      "AUC           : 0.9923\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 310397, FP: 6117\n",
      "FN: 2950, TP: 100532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# === 0. Reproducibilidad ===\n",
    "np.random.seed(42)\n",
    "\n",
    "# === 1. Cargar dataset unificado y normalizado ===\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2. Separar features y label ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Manejo de infinitos -> NaN (para que el imputer los resuelva)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3. Split estratificado y reproducible ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Pipeline: Imputer (median) -> LDA ===\n",
    "# Nota: shrinkage='auto' requiere solver='lsqr' o 'eigen'\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"lda\", LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "])\n",
    "\n",
    "# Entrenamiento\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Predicción y métricas ===\n",
    "y_pred = pipe.predict(X_test)\n",
    "# LDA soporta predict_proba\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "# === 6. Resultados ===\n",
    "print(\"=== Classification Metrics (LDA) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395eac2e-1d27-47dd-985c-6b2dc1aefa15",
   "metadata": {},
   "source": [
    "### LDA (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef4ba48e-4c45-4694-95d1-25860a68abbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (LDA + SMOTE) ===\n",
      "Accuracy      : 0.9735\n",
      "Precision     : 0.9156\n",
      "Recall        : 0.9830\n",
      "F1-Score      : 0.9481\n",
      "FAR           : 0.0296\n",
      "AUC           : 0.9924\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 307136, FP: 9378\n",
      "FN: 1755, TP: 101727\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline  # importante: pipeline de imblearn\n",
    "\n",
    "# === 0. Reproducibilidad ===\n",
    "np.random.seed(42)\n",
    "\n",
    "# === 1. Cargar dataset unificado y normalizado ===\n",
    "# Debe tener todas las columnas numéricas y 'Label' (0/1) al final\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2. Separar features y label ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Manejo de infinitos -> NaN (para que el imputer los resuelva)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3. Split estratificado y reproducible ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Pipeline: Imputer (median) -> SMOTE -> LDA ===\n",
    "# shrinkage='auto' con solver='lsqr' mejora estabilidad en alta dimensión\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"lda\", LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "])\n",
    "\n",
    "# Entrenamiento\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Predicción y métricas ===\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "# === 6. Resultados ===\n",
    "print(\"=== Classification Metrics (LDA + SMOTE) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ba064-dc4e-4fef-b38a-590cfe0a27ec",
   "metadata": {},
   "source": [
    "### Autoencoder + Logistic Regression (no SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c264b57-c6b1-481b-9cb8-8cd5c3f3033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (AE Embeddings + Logistic Regression, no SMOTE) ===\n",
      "Accuracy      : 0.9859\n",
      "Precision     : 0.9691\n",
      "Recall        : 0.9738\n",
      "F1-Score      : 0.9715\n",
      "FAR           : 0.0101\n",
      "AUC           : 0.9960\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 313306, FP: 3208\n",
      "FN: 2709, TP: 100773\n"
     ]
    }
   ],
   "source": [
    "# === Autoencoder + Logistic Regression (sin SMOTE), reproducible ===\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# ---- Reproducibilidad (antes de importar TF) ----\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # opcional: fuerza CPU\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# === 1) Cargar dataset unificado y normalizado ===\n",
    "# Debe tener todas las columnas numéricas y la última llamada 'Label' (0/1)\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2) Separar features y etiqueta ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Manejo de infinitos -> NaN (para que el imputer los resuelva)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3) Split estratificado y reproducible ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4) Imputación (sin SMOTE) ===\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_test_imp  = imputer.transform(X_test)\n",
    "\n",
    "# === 5) Autoencoder (determinista) ===\n",
    "input_dim = X_train_imp.shape[1]\n",
    "encoding_dim = 32  # puedes ajustar\n",
    "\n",
    "inp = Input(shape=(input_dim,))\n",
    "h1 = Dense(64, activation='relu')(inp)\n",
    "z  = Dense(encoding_dim, activation='relu')(h1)\n",
    "h2 = Dense(64, activation='relu')(z)\n",
    "out = Dense(input_dim, activation='sigmoid')(h2)\n",
    "\n",
    "autoencoder = Model(inputs=inp, outputs=out)\n",
    "encoder = Model(inputs=inp, outputs=z)\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "\n",
    "# Importante: shuffle=False para reproducibilidad (validation_split toma el último 10%)\n",
    "autoencoder.fit(\n",
    "    X_train_imp, X_train_imp,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    validation_split=0.1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# === 6) Embeddings ===\n",
    "X_train_emb = encoder.predict(X_train_imp, verbose=0)\n",
    "X_test_emb  = encoder.predict(X_test_imp,  verbose=0)\n",
    "\n",
    "# === 7) Clasificador: Regresión Logística (sin SMOTE) ===\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train_emb, y_train)\n",
    "\n",
    "# === 8) Predicciones y métricas ===\n",
    "y_pred = clf.predict(X_test_emb)\n",
    "y_proba = clf.predict_proba(X_test_emb)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "print(\"=== Classification Metrics (AE Embeddings + Logistic Regression, no SMOTE) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90ce43-ae05-4cc4-81ef-9e8207788bc0",
   "metadata": {},
   "source": [
    "### Autoencoder + Logistic Regression (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb48bb4-3f5d-4f19-9944-621049233a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics (AE Embeddings + SMOTE + Logistic Regression) ===\n",
      "Accuracy      : 0.9806\n",
      "Precision     : 0.9428\n",
      "Recall        : 0.9805\n",
      "F1-Score      : 0.9613\n",
      "FAR           : 0.0194\n",
      "AUC           : 0.9954\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "TN: 310363, FP: 6151\n",
      "FN: 2016, TP: 101466\n"
     ]
    }
   ],
   "source": [
    "# === Autoencoder + SMOTE + Logistic Regression (reproducible) ===\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ---- Reproducibilidad (antes de importar TF) ----\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # opcional: fuerza CPU\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# === 1) Cargar dataset unificado y normalizado ===\n",
    "# Debe tener todas las columnas numéricas y la última llamada 'Label' (0/1)\n",
    "df = pd.read_csv(\"CICIDS2017_improved_unified.csv\")\n",
    "\n",
    "# === 2) Separar features y etiqueta ===\n",
    "X = df.iloc[:, :-1].copy()\n",
    "y = df.iloc[:, -1].astype(int).copy()\n",
    "\n",
    "# Manejo de infinitos -> NaN (para que el imputer los resuelva)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === 3) Split estratificado y reproducible ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4) Imputación (sin SMOTE todavía) ===\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_test_imp  = imputer.transform(X_test)\n",
    "\n",
    "# === 5) Autoencoder (determinista) ===\n",
    "input_dim = X_train_imp.shape[1]\n",
    "encoding_dim = 32  # puedes ajustar\n",
    "\n",
    "inp = Input(shape=(input_dim,))\n",
    "h1 = Dense(64, activation='relu')(inp)\n",
    "z  = Dense(encoding_dim, activation='relu')(h1)\n",
    "h2 = Dense(64, activation='relu')(z)\n",
    "out = Dense(input_dim, activation='sigmoid')(h2)\n",
    "\n",
    "autoencoder = Model(inputs=inp, outputs=out)\n",
    "encoder = Model(inputs=inp, outputs=z)\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "\n",
    "# Nota: shuffle=False para reproducibilidad (validation_split toma el último 10%)\n",
    "autoencoder.fit(\n",
    "    X_train_imp, X_train_imp,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    validation_split=0.1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# === 6) Embeddings ===\n",
    "X_train_emb = encoder.predict(X_train_imp, verbose=0)\n",
    "X_test_emb  = encoder.predict(X_test_imp,  verbose=0)\n",
    "\n",
    "# === 7) SMOTE sobre embeddings de TRAIN (sin fuga) ===\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_emb_sm, y_train_sm = sm.fit_resample(X_train_emb, y_train)\n",
    "\n",
    "# === 8) Clasificador: Regresión Logística ===\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train_emb_sm, y_train_sm)\n",
    "\n",
    "# === 9) Predicciones y métricas ===\n",
    "y_pred = clf.predict(X_test_emb)\n",
    "y_proba = clf.predict_proba(X_test_emb)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Alarm Rate\n",
    "\n",
    "print(\"=== Classification Metrics (AE Embeddings + SMOTE + Logistic Regression) ===\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"FAR           : {far:.4f}\")\n",
    "print(f\"AUC           : {auc:.4f}\")\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849f3b1-f92c-4c9d-9b0b-195f10501e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
